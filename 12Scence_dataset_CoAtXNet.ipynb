{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOi1mjLvjIV2liCyswseAFm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Husseinhhameed/CoAtXnet/blob/main/12Scence_dataset_CoAtXNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VZZ4JWpU4I7",
        "outputId": "c9071c33-ff0a-4bcd-9f4c-b17d39799fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transforms3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeExgCUQU4vl",
        "outputId": "979f4143-aa77-4a7f-f6d2-526ec8ea44e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transforms3d\n",
            "  Downloading transforms3d-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from transforms3d) (1.26.4)\n",
            "Downloading transforms3d-0.4.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transforms3d\n",
            "Successfully installed transforms3d-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE-gk6b4U5_q",
        "outputId": "8b0a2bab-901c-4f0d-863d-ab81d25a487d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomRotation, ToTensor\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from torchvision.utils import make_grid\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import transforms3d.quaternions as txq\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import re\n"
      ],
      "metadata": {
        "id": "vuZza9yNU7SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ModifiedDSACLoss(y_true, y_pred, weight_translation_initial=1.0, weight_quaternion_initial=1.0):\n",
        "    # Split the true and predicted values into delta positions and quaternions\n",
        "    true_positions, true_quaternions = torch.split(y_true, [3, 4], dim=-1)\n",
        "    pred_positions, pred_quaternions = torch.split(y_pred, [3, 4], dim=-1)\n",
        "\n",
        "    # Normalize the predicted quaternions\n",
        "    pred_quaternions = F.normalize(pred_quaternions, p=2, dim=-1)\n",
        "\n",
        "    # Calculate the translation error (L2 distance)\n",
        "    t_error = torch.sqrt(torch.sum((true_positions - pred_positions) ** 2, dim=-1))\n",
        "    mean_t_error = torch.mean(t_error)\n",
        "\n",
        "    # Calculate the quaternion angle error\n",
        "    dot_product = torch.sum(true_quaternions * pred_quaternions, dim=-1)\n",
        "    dot_product = torch.clamp(dot_product, -1.0, 1.0)  # Ensure dot product is within [-1, 1] to avoid NaNs in acos\n",
        "    angle_error = 2.0 * torch.acos(torch.abs(dot_product))\n",
        "    mean_q_error = torch.mean(angle_error)\n",
        "\n",
        "    # Dynamic weight adjustment based on the error ratio\n",
        "    error_ratio = mean_t_error / (mean_q_error + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
        "    weight_translation = weight_translation_initial * error_ratio\n",
        "    weight_quaternion = weight_quaternion_initial / error_ratio\n",
        "\n",
        "    # Apply dynamic weights to the respective errors\n",
        "    weighted_t_error = weight_translation * mean_t_error\n",
        "    weighted_q_error = weight_quaternion * mean_q_error\n",
        "\n",
        "    # Final combined weighted error\n",
        "    combined_weighted_error = weighted_t_error + weighted_q_error\n",
        "\n",
        "    return combined_weighted_error\n"
      ],
      "metadata": {
        "id": "xPbWACDhU8aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to extract frame numbers from filenames\n",
        "def extract_frame_number(filename):\n",
        "    match = re.search(r'frame-(\\d+)', filename)\n",
        "    return int(match.group(1)) if match else -1\n",
        "\n",
        "# Function to process poses\n",
        "def process_poses(poses_in, mean_t, std_t, align_R, align_t, align_s):\n",
        "    poses_out = np.zeros((len(poses_in), 7))\n",
        "    poses_out[:, 0:3] = poses_in[:, [3, 7, 11]]  # Translation components\n",
        "\n",
        "    # Align and process rotation\n",
        "    for i in range(len(poses_out)):\n",
        "        R = poses_in[i].reshape((3, 4))[:3, :3]\n",
        "        q = txq.mat2quat(np.dot(align_R, R))\n",
        "        q *= np.sign(q[0])  # Constrain to hemisphere\n",
        "        poses_out[i, 3:] = q  # Keep the quaternion as 4D\n",
        "        t = poses_out[i, :3] - align_t\n",
        "        poses_out[i, :3] = align_s * np.dot(align_R, t[:, np.newaxis]).squeeze()\n",
        "\n",
        "    # Normalize translation\n",
        "    poses_out[:, :3] -= mean_t\n",
        "    poses_out[:, :3] /= std_t\n",
        "\n",
        "    return poses_out\n",
        "\n",
        "# Function to load and process poses\n",
        "def load_and_process_poses(data_dir, train=True, real=False, vo_lib='orbslam'):\n",
        "    ps = []\n",
        "    vo_stats = {'R': np.eye(3), 't': np.zeros(3), 's': 1}\n",
        "    pose_files = [f for f in os.listdir(data_dir) if f.endswith('.pose.txt')]\n",
        "    pose_files.sort(key=extract_frame_number)\n",
        "\n",
        "    for filename in pose_files:\n",
        "        pose_path = os.path.join(data_dir, filename)\n",
        "        if os.path.exists(pose_path):\n",
        "            pose = np.loadtxt(pose_path).flatten()[:12]\n",
        "            ps.append(pose)\n",
        "\n",
        "    ps = np.array(ps)\n",
        "    pose_stats_filename = os.path.join(data_dir, 'pose_stats.txt')\n",
        "    if train and not real:\n",
        "        mean_t = np.mean(ps[:, [3, 7, 11]], axis=0)\n",
        "        std_t = np.std(ps[:, [3, 7, 11]], axis=0)\n",
        "        np.savetxt(pose_stats_filename, np.vstack((mean_t, std_t)), fmt='%8.7f')\n",
        "    else:\n",
        "        mean_t, std_t = np.loadtxt(pose_stats_filename)\n",
        "\n",
        "    # Process and normalize poses\n",
        "    processed_poses = process_poses(poses_in=ps, mean_t=mean_t, std_t=std_t,\n",
        "                                    align_R=vo_stats['R'], align_t=vo_stats['t'],\n",
        "                                    align_s=vo_stats['s'])\n",
        "    return processed_poses\n",
        "\n",
        "# Define the transformation for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Dataset class\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = self._load_samples()\n",
        "        self.processed_poses = self._load_processed_poses()\n",
        "\n",
        "        print(f\"Number of samples: {len(self.samples)}\")\n",
        "        print(f\"Number of processed poses: {self.processed_poses.shape[0]}\")\n",
        "\n",
        "        if len(self.samples) != self.processed_poses.shape[0]:\n",
        "            raise ValueError(\"Mismatch between number of samples and processed poses.\")\n",
        "\n",
        "    def _load_samples(self):\n",
        "        samples = []\n",
        "        color_files = [f for f in os.listdir(self.root_dir) if f.endswith('.color.jpg')]\n",
        "        depth_files = [f for f in os.listdir(self.root_dir) if f.endswith('.depth.png')]\n",
        "        pose_files = [f for f in os.listdir(self.root_dir) if f.endswith('.pose.txt')]\n",
        "\n",
        "        color_files.sort(key=extract_frame_number)\n",
        "        depth_files.sort(key=extract_frame_number)\n",
        "        pose_files.sort(key=extract_frame_number)\n",
        "\n",
        "        for color_file, depth_file, pose_file in zip(color_files, depth_files, pose_files):\n",
        "            samples.append((os.path.join(self.root_dir, color_file),\n",
        "                            os.path.join(self.root_dir, depth_file),\n",
        "                            os.path.join(self.root_dir, pose_file)))\n",
        "        return samples\n",
        "\n",
        "    def _load_processed_poses(self):\n",
        "        return load_and_process_poses(self.root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        color_path, depth_path, _ = self.samples[idx]\n",
        "\n",
        "        # Read and process color image\n",
        "        color_image = cv2.imread(color_path, cv2.IMREAD_COLOR)\n",
        "        if color_image is None:\n",
        "            raise FileNotFoundError(f\"Color image not found at {color_path}\")\n",
        "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Read and process depth image\n",
        "        depth_image = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n",
        "        if depth_image is None:\n",
        "            raise FileNotFoundError(f\"Depth image not found at {depth_path}\")\n",
        "\n",
        "        # Get the corresponding pose\n",
        "        pose_matrix = self.processed_poses[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            color_image = self.transform(color_image)\n",
        "\n",
        "            # Normalize depth image and convert to uint8\n",
        "            max_depth = depth_image.max()\n",
        "            if max_depth > 0:\n",
        "                depth_image = (depth_image / max_depth * 255).astype(np.uint8)\n",
        "            else:\n",
        "                depth_image = np.zeros_like(depth_image, dtype=np.uint8)\n",
        "            depth_image = self.transform(depth_image)\n",
        "\n",
        "        return color_image, depth_image, pose_matrix"
      ],
      "metadata": {
        "id": "rI1O2oBMU9n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
        "    stride = 1 if downsample == False else 2\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.GELU()\n",
        "    )\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn, norm):\n",
        "        super().__init__()\n",
        "        self.norm = norm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class SE(nn.Module):\n",
        "    def __init__(self, inp, oup, expansion=0.25):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(oup, int(inp * expansion), bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(inp * expansion), oup, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class XMBConv(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        stride = 1 if self.downsample == False else 2\n",
        "        hidden_dim = int(inp * expansion)\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "            self.poolx = nn.MaxPool2d(3, 2, 1)\n",
        "            self.projx = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        if expansion == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
        "                          1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "            self.convx = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
        "                          1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                # down-sample in the first conv\n",
        "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
        "                          groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                SE(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "            self.convx = nn.Sequential(\n",
        "                # pw\n",
        "                # down-sample in the first conv\n",
        "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
        "                          groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                SE(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
        "        self.convx = PreNorm(inp, self.convx, nn.BatchNorm2d)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x[1]\n",
        "        x = x[0]\n",
        "\n",
        "        if self.downsample:\n",
        "            out1 = self.proj(self.pool(x)) + self.conv(x)\n",
        "            out2 = self.projx(self.poolx(y)) + self.convx(y)\n",
        "        else:\n",
        "            out1 = x + self.conv(x)\n",
        "            out2 = y + self.convx(y)\n",
        "        return [out1, out2]\n",
        "\n",
        "class XAttention(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == inp)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        # parameter table of relative position bias\n",
        "        self.relative_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
        "\n",
        "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
        "        coords = torch.flatten(torch.stack(coords), 1)\n",
        "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "        relative_coords[0] += self.ih - 1\n",
        "        relative_coords[1] += self.iw - 1\n",
        "        relative_coords[0] *= 2 * self.iw - 1\n",
        "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
        "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
        "        self.register_buffer(\"relative_index\", relative_index)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n",
        "        self.to_kx = nn.Linear(inp, inner_dim * 1, bias=False)\n",
        "        self.to_qx = nn.Linear(inp, inner_dim * 1, bias=False)\n",
        "\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, oup),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        kx = self.to_kx(y)\n",
        "        qx = self.to_qx(x)\n",
        "\n",
        "        q, k, v = map(lambda t: rearrange(\n",
        "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "        kx = rearrange(kx, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        qx = rearrange(qx, 'b n (h d) -> b h n d', h=self.heads)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # Use \"gather\" for more efficiency on GPUs\n",
        "        relative_bias = self.relative_bias_table.gather(\n",
        "            0, self.relative_index.repeat(1, self.heads))\n",
        "        relative_bias = rearrange(\n",
        "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
        "        dots = dots + relative_bias\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "        out = torch.matmul(attn, v)\n",
        "\n",
        "        dots = torch.matmul(qx, kx.transpose(-1, -2)) * self.scale\n",
        "        dots = dots + relative_bias\n",
        "        attn = self.attend(dots)\n",
        "        out = torch.matmul(attn, out)\n",
        "\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class XTransformer(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(inp * 4)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "        self.downsample = downsample\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(inp)\n",
        "        self.layer_normx = nn.LayerNorm(inp)\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "            self.pool1x = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2x = nn.MaxPool2d(3, 2, 1)\n",
        "            self.projx = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "        self.attn = XAttention(inp, oup, image_size, heads, dim_head, dropout)\n",
        "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
        "        self.attnx = XAttention(inp, oup, image_size, heads, dim_head, dropout)\n",
        "        self.ffx = FeedForward(oup, hidden_dim, dropout)\n",
        "\n",
        "\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            )\n",
        "        self.ffx = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(oup, self.ffx, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x[1]\n",
        "        x = x[0]\n",
        "\n",
        "        if self.downsample:\n",
        "            pool1 = self.pool2(x)\n",
        "            pool1 = rearrange(pool1, 'b c ih iw -> b (ih iw) c')\n",
        "            norm1 = self.layer_norm(pool1)\n",
        "            pool2 = self.pool2x(y)\n",
        "            pool2 = rearrange(pool2, 'b c ih iw -> b (ih iw) c')\n",
        "            norm2 = self.layer_normx(pool2)\n",
        "\n",
        "            attn1 = self.attn(norm1, norm2)\n",
        "            attn1 = rearrange(attn1, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            attn2 = self.attnx(norm2, norm1)\n",
        "            attn2 = rearrange(attn2, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "\n",
        "            out1 = self.proj(self.pool1(x)) + attn1\n",
        "            out2 = self.projx(self.pool1x(y)) + attn2\n",
        "        else:\n",
        "            xx = rearrange(x, 'b c ih iw -> b (ih iw) c')\n",
        "            norm1 = self.layer_norm(xx)\n",
        "            yy = rearrange(y, 'b c ih iw -> b (ih iw) c')\n",
        "            norm2 = self.layer_normx(yy)\n",
        "\n",
        "            attn1 = self.attn(norm1, norm2)\n",
        "            attn1 = rearrange(attn1, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            attn2 = self.attnx(norm2, norm1)\n",
        "            attn2 = rearrange(attn2, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            out1 = x + attn1\n",
        "            out2 = y + attn2\n",
        "\n",
        "        out1 = out1 + self.ff(out1)\n",
        "        out2 = out2 + self.ffx(out2)\n",
        "        return [out1, out2]\n",
        "\n",
        "\n",
        "class CoAtXNet(nn.Module):\n",
        "    def __init__(self, image_size, in_channels, aux_channels, num_blocks, channels, block_types=['C', 'C', 'T', 'T']):\n",
        "        super().__init__()\n",
        "        ih, iw = image_size\n",
        "        block = {'C': XMBConv, 'T': XTransformer}\n",
        "\n",
        "        self.s0 = self._make_layer(\n",
        "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
        "        self.s0x = self._make_layer(\n",
        "            conv_3x3_bn, aux_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
        "\n",
        "        self.s1 = self._make_layer(\n",
        "            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
        "        self.s2 = self._make_layer(\n",
        "            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
        "        self.s3 = self._make_layer(\n",
        "            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
        "        self.s4 = self._make_layer(\n",
        "            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
        "\n",
        "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
        "        hidden_dim = 1024\n",
        "        self.fc1 = nn.Linear(channels[-1] * 2, hidden_dim)\n",
        "        self.relu = nn.ReLU()  # Activation function between dense layers\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)  # Another dense layer\n",
        "        self.fc3 = nn.Linear(hidden_dim // 2, 7)  # Final output layer adjusted to target size\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        x = self.s0(x)\n",
        "        y = self.s0x(y)\n",
        "\n",
        "        xy = self.s1([x,y])\n",
        "        xy = self.s2(xy)\n",
        "        xy = self.s3(xy)\n",
        "        xy = self.s4(xy)\n",
        "\n",
        "        x = xy[0]\n",
        "        y = xy[1]\n",
        "\n",
        "        x = self.pool(x).view(-1, x.shape[1])\n",
        "        y = self.pool(y).view(-1, y.shape[1])\n",
        "\n",
        "        x = torch.cat((x,y), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
        "        layers = nn.ModuleList([])\n",
        "        for i in range(depth):\n",
        "            if i == 0:\n",
        "                layers.append(block(inp, oup, image_size, downsample=True))\n",
        "            else:\n",
        "                layers.append(block(oup, oup, image_size))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "def coatxnet_0():\n",
        "    num_blocks = [2, 2, 3, 5, 2]            # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoAtXNet((256, 256), 3, 1, num_blocks, channels, )\n",
        "\n",
        "\n",
        "def coatxnet_1():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoAtXNet((256, 256), 3, 1, num_blocks, channels, )\n",
        "\n",
        "\n",
        "def coatxnet_2():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [128, 128, 256, 512, 1026]   # D\n",
        "    return CoAtXNet((256, 256), 3, 1, num_blocks, channels, )\n",
        "\n",
        "\n",
        "def coatxnet_3():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoAtXNet((256, 256), 3, 1, num_blocks, channels, )\n",
        "\n",
        "\n",
        "def coatxnet_4():\n",
        "    num_blocks = [2, 2, 12, 28, 2]          # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoAtXNet((256, 256), 3, 1, num_blocks, channels, )\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img = torch.randn(1, 3, 256, 256)\n",
        "    aux = torch.randn(1, 1, 256, 256)\n",
        "\n",
        "    net = coatxnet_0()\n",
        "    out = net(img, aux)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatxnet_1()\n",
        "    out = net(img, aux)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatxnet_2()\n",
        "    out = net(img, aux)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatxnet_3()\n",
        "    out = net(img, aux)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = coatxnet_4()\n",
        "    out = net(img, aux)\n",
        "    print(out.shape, count_parameters(net))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDgyQMCfU-yh",
        "outputId": "6f1354e5-16c8-4710-e1e7-00bc150cd7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7]) 39113847\n",
            "torch.Size([1, 7]) 73448199\n",
            "torch.Size([1, 7]) 120818047\n",
            "torch.Size([1, 7]) 249078535\n",
            "torch.Size([1, 7]) 432612327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    root_dir = '/content/drive/MyDrive/12-Scense/apt1/living/data'\n",
        "    dataset = FireDataset(root_dir=root_dir, transform=transform)\n",
        "\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    num_epochs = 100  # Define the number of epochs\n",
        "\n",
        "    # Check for GPU availability\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f'Fold {fold + 1}')\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "        train_loader = DataLoader(dataset, batch_size=16, sampler=train_sampler, num_workers=4)\n",
        "        val_loader = DataLoader(dataset, batch_size=16, sampler=val_sampler, num_workers=4)\n",
        "\n",
        "        model = coatxnet_1().to(device)  # Move model to GPU\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.1)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            for color_images, depth_images, poses in tqdm(train_loader):\n",
        "                color_images, depth_images, poses = color_images.to(device), depth_images.to(device), poses.to(device)  # Move data to GPU\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(color_images, depth_images)\n",
        "                loss = ModifiedDSACLoss(poses, outputs)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            # Validation loop\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for color_images, depth_images, poses in val_loader:\n",
        "                    color_images, depth_images, poses = color_images.to(device), depth_images.to(device), poses.to(device)  # Move data to GPU\n",
        "                    outputs = model(color_images, depth_images)\n",
        "                    loss = ModifiedDSACLoss(poses, outputs)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "            # Step the scheduler\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            print(f'Epoch {epoch + 1}, Train Loss: {train_loss / len(train_loader)}, Val Loss: {val_loss / len(val_loader)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_13qeB1YVBIm",
        "outputId": "5462e87c-269b-476c-9990-d5290329def6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 1528\n",
            "Number of processed poses: 1528\n",
            "Using device: cuda\n",
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:56<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 2.072328303062944, Val Loss: 2.494295763351945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:51<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 1.2727857613115212, Val Loss: 1.036811010035882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 0.9768855484260851, Val Loss: 0.8662330734260406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.843186569762465, Val Loss: 0.9122369341924808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 0.7475745154278491, Val Loss: 0.5908044438338605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 0.639247814247892, Val Loss: 0.5550305825158682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 0.6055205736821808, Val Loss: 0.4744993823600585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 0.523979890101342, Val Loss: 0.5085714862093688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.4634256213071149, Val Loss: 0.4729018904899952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.4750901092540258, Val Loss: 0.41193860970568474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 0.516185639210243, Val Loss: 0.4729047711058839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 0.41925692052593627, Val Loss: 0.3485435430603486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 0.3540437111748613, Val Loss: 0.3614929090286971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 0.4088431346805357, Val Loss: 0.3845573378971928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 0.381948138947756, Val Loss: 0.3164068551686605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 0.328044555571106, Val Loss: 0.30799316094036966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 0.3252420235510637, Val Loss: 0.3563695046372598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 0.33265807483870025, Val Loss: 0.35995830281343666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 0.4014612808178525, Val Loss: 0.32209474002104244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 0.3327822263701255, Val Loss: 0.3453987339784173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train Loss: 0.3110412321339518, Val Loss: 0.33246333164513203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train Loss: 0.22169944084340354, Val Loss: 0.20814580164458102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train Loss: 0.17775325524369323, Val Loss: 0.17787409857365097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train Loss: 0.16014766658463414, Val Loss: 0.17045557501592853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train Loss: 0.14842619957912437, Val Loss: 0.15677044642097632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train Loss: 0.14456519693592862, Val Loss: 0.16773152176523992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train Loss: 0.1439904901673825, Val Loss: 0.14344106691252584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Train Loss: 0.1337606690443588, Val Loss: 0.1497787066095297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Train Loss: 0.13093934903633125, Val Loss: 0.14236595389735268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Train Loss: 0.12712536584360098, Val Loss: 0.14723221738927084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Train Loss: 0.12016344827835677, Val Loss: 0.17122375033190068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Train Loss: 0.12263334221265082, Val Loss: 0.14480630850820522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Train Loss: 0.12048695428568124, Val Loss: 0.1408036843138683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Train Loss: 0.11115766484903705, Val Loss: 0.1389001880152764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Train Loss: 0.1147133452927346, Val Loss: 0.14136187513010132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Train Loss: 0.11165816242886337, Val Loss: 0.14739826953746593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Train Loss: 0.10515114559576516, Val Loss: 0.12759148125794229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Train Loss: 0.10138757891795437, Val Loss: 0.13904046453565952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Train Loss: 0.10245447786599446, Val Loss: 0.13258313433179522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Train Loss: 0.104509706078322, Val Loss: 0.13783220861974926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Train Loss: 0.10260272188280187, Val Loss: 0.1257864091937678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Train Loss: 0.10632021572984812, Val Loss: 0.13412370791559164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Train Loss: 0.09943270458266136, Val Loss: 0.12486940568295071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Train Loss: 0.09514083572587285, Val Loss: 0.13436339651462798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Train Loss: 0.09419031399682326, Val Loss: 0.13671603179020658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Train Loss: 0.10031795945847137, Val Loss: 0.1258221665407692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Train Loss: 0.09969867719764074, Val Loss: 0.11945489906823356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Train Loss: 0.08953750248698997, Val Loss: 0.13041351740709056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Train Loss: 0.09848669770660831, Val Loss: 0.12767382123766327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Train Loss: 0.08345185620770276, Val Loss: 0.12923133327851188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51, Train Loss: 0.0873342704063732, Val Loss: 0.1369958835810472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52, Train Loss: 0.08632880800593333, Val Loss: 0.1272938673996975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53, Train Loss: 0.0736090533749387, Val Loss: 0.12626089187620454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54, Train Loss: 0.07083755994318562, Val Loss: 0.12173106612845133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55, Train Loss: 0.06643919964576617, Val Loss: 0.11807227536771996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56, Train Loss: 0.0637227689046717, Val Loss: 0.1183331946890512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Train Loss: 0.06640171775752372, Val Loss: 0.12404548245873974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58, Train Loss: 0.06766977338771078, Val Loss: 0.1233881800641752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59, Train Loss: 0.06385319858739961, Val Loss: 0.1284548838248405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60, Train Loss: 0.06571405809812682, Val Loss: 0.11693665631702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Train Loss: 0.06382831861269898, Val Loss: 0.11304953518520619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62, Train Loss: 0.06549969618900849, Val Loss: 0.11686790680880879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63, Train Loss: 0.06361175109609923, Val Loss: 0.11904935129746877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64, Train Loss: 0.06763482371805568, Val Loss: 0.12335452215232394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65, Train Loss: 0.06446347522283241, Val Loss: 0.13842804821585344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66, Train Loss: 0.06304934860408336, Val Loss: 0.11283054354186621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67, Train Loss: 0.06178970711192597, Val Loss: 0.11558238843774984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:52<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68, Train Loss: 0.06304435657664595, Val Loss: 0.1216596076487813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 42/77 [00:30<00:25,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-611492fb6772>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Validation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}